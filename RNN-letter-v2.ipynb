{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import bcolz\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "# path = get_file(fname = 'allPyPrograms_no_comments.txt', origin = 'file:///homw/wtemp/585/allPyPrograms_no_comments.txt')\n",
    "path = os.getcwd() + '/allPyPrograms_no_comments.txt'\n",
    "text_all = open(path).read()\n",
    "text = text_all[:1000000]\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('def sort_blocks():\\n'\n",
      " \"    with open('README.md', 'r') as read_me_file:\\n\"\n",
      " '        read_me = read_me_file.read()\\n'\n",
      " \"    table_of_contents = ''.join(read_me.split('- - -')[0])\\n\"\n",
      " \"    blocks = ''.join(read_me.split('- - -')[1]).split('\\\\n# ')\\n\"\n",
      " '    for i in range(len(blocks)):\\n'\n",
      " '        if i == 0:\\n'\n",
      " '            blocks[i]')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(len(chars)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {v:i for i,v in enumerate(chars)}\n",
    "index_to_char = {i:v for i,v in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_index = [char_to_index[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70, 71, 72, 2, 85, 81, 84, 86, 65, 68]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def sort_blocks():\\n    wi'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index_to_char[i] for i in total_index[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num = 3\n",
    "xin = [[total_index[j+i] for j in range(0, len(total_index)-1-pred_num, pred_num)] for i in range(pred_num)]\n",
    "y = [total_index[i+pred_num] for i in range(0, len(total_index)-1-pred_num, pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.stack(xin[i][:-2]) for i in range(pred_num)]\n",
    "Y = np.stack(y[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([70,  2, 84, ...,  2,  2, 75]),\n",
      " array([71, 85, 86, ...,  2,  9, 71]),\n",
      " array([72, 81, 65, ...,  2, 88, 89])]\n"
     ]
    }
   ],
   "source": [
    "pprint(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 84, 68, 69, 10,  1,  2, 75])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((333330,), (333330,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 256\n",
    "vocab_size = len(chars)+1\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, activation='relu'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 3, 42)             10416     \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 248)               63736     \n",
      "=================================================================\n",
      "Total params: 150,696\n",
      "Trainable params: 150,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.3134\n",
      "Epoch 2/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.3115\n",
      "Epoch 3/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.3090\n",
      "Epoch 4/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.3070\n",
      "Epoch 5/25\n",
      "333330/333330 [==============================] - 108s 324us/step - loss: 1.3044\n",
      "Epoch 6/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.3033\n",
      "Epoch 7/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.3008\n",
      "Epoch 8/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.2989\n",
      "Epoch 9/25\n",
      "333330/333330 [==============================] - 107s 322us/step - loss: 1.2970\n",
      "Epoch 10/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.2947\n",
      "Epoch 11/25\n",
      "333330/333330 [==============================] - 108s 323us/step - loss: 1.2940\n",
      "Epoch 12/25\n",
      "333330/333330 [==============================] - 107s 322us/step - loss: 1.2914\n",
      "Epoch 13/25\n",
      "333330/333330 [==============================] - 91s 272us/step - loss: 1.2910\n",
      "Epoch 14/25\n",
      "333330/333330 [==============================] - 76s 227us/step - loss: 1.2893\n",
      "Epoch 15/25\n",
      "333330/333330 [==============================] - 76s 227us/step - loss: 1.2868\n",
      "Epoch 16/25\n",
      "333330/333330 [==============================] - 76s 228us/step - loss: 1.2852\n",
      "Epoch 17/25\n",
      "333330/333330 [==============================] - 76s 228us/step - loss: 1.2851\n",
      "Epoch 18/25\n",
      "333330/333330 [==============================] - 76s 229us/step - loss: 1.2832\n",
      "Epoch 19/25\n",
      "333330/333330 [==============================] - 76s 228us/step - loss: 1.2821\n",
      "Epoch 20/25\n",
      "333330/333330 [==============================] - 76s 229us/step - loss: 1.2813\n",
      "Epoch 21/25\n",
      "333330/333330 [==============================] - 76s 228us/step - loss: 1.2787\n",
      "Epoch 22/25\n",
      "333330/333330 [==============================] - 75s 226us/step - loss: 1.2786\n",
      "Epoch 23/25\n",
      "333330/333330 [==============================] - 76s 229us/step - loss: 1.2776\n",
      "Epoch 24/25\n",
      "333330/333330 [==============================] - 76s 229us/step - loss: 1.2766\n",
      "Epoch 25/25\n",
      "333330/333330 [==============================] - 76s 228us/step - loss: 1.2752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73651ed9b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.stack(X, 1), Y, batch_size=64, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_3pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_3pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_7pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_7pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(inp):\n",
    "    index = [char_to_index[i] for i in inp]\n",
    "    arr = np.expand_dims(np.array(index), axis=0)\n",
    "    prediction = model.predict(arr)\n",
    "    return index_to_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char(' de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('t34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"while True: thefuck.rules.get_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in return self._downloader.pat_new_command('git in r\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = \"while True:\"\n",
    "for i in range(1000):\n",
    "    prog = prog + predict_next_char(prog[-3:]).replace('\\n', ' ')\n",
    "prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_model1(observed_seq):\n",
    "    # Get the last letter\n",
    "    last_item = observed_seq[-1]\n",
    "    word = \"\"\n",
    "    thresh = 100\n",
    "    while thresh > 0 and (len(word) < 1 or word[-1] != \" \"):\n",
    "        thresh -= 1\n",
    "        if len(word) > 100:\n",
    "            return word\n",
    "        seen = observed_seq + word\n",
    "        p = predict_next_char(seen[-3:])\n",
    "        word = word + p\n",
    "        last_item = p\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy.py  has no hole to predict\n",
      "(b'', b'')\n",
      "(b'', b'')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 17, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,os\n",
    "import subprocess\n",
    "import evalerr\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "TEST_DIR = '/home/wtemp/585/error/Test_Dataset/'\n",
    "\n",
    "HOLE = \"PREDICTION_HOLE_PLACEHOLDER\"\n",
    "\n",
    "PRED_DIR = \"/home/wtemp/585/error/Predicted_Results/\"\n",
    "result_dict={}\n",
    "\n",
    "evalerr.test(recom_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of Second Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [[total_index[j+i] for j in range(1, len(total_index)-pred_num, pred_num)] for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_return = [np.stack(ys[i][:-2]) for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([70,  2, 84, ...,  2,  2, 75]),\n",
       " array([71, 85, 86, ...,  2,  9, 71]),\n",
       " array([72, 81, 65, ...,  2, 88, 89])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([71, 85, 86, ...,  2,  9, 71]),\n",
       " array([72, 81, 65, ...,  2, 88, 89]),\n",
       " array([ 2, 84, 68, ...,  2, 75, 65])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 247\n",
    "n_fac = 42\n",
    "hidden_layers = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, return_sequences=True, activation='relu'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 3, 42)             10374     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 3, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 3, 247)            63479     \n",
      "=================================================================\n",
      "Total params: 150,397\n",
      "Trainable params: 150,397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "return_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = np.stack(X, 1)\n",
    "Y_model = np.expand_dims(np.stack(Y_return, 1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333330/333330 [==============================] - 68s 204us/step - loss: 2.3099\n",
      "Epoch 2/5\n",
      "333330/333330 [==============================] - 63s 190us/step - loss: 2.0601\n",
      "Epoch 3/5\n",
      "333330/333330 [==============================] - 72s 217us/step - loss: 2.0093\n",
      "Epoch 4/5\n",
      "333330/333330 [==============================] - 72s 217us/step - loss: 1.9826\n",
      "Epoch 5/5\n",
      "333330/333330 [==============================] - 73s 218us/step - loss: 1.9645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f735fe32390>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333330/333330 [==============================] - 72s 215us/step - loss: 1.9513\n",
      "Epoch 2/5\n",
      "333330/333330 [==============================] - 63s 188us/step - loss: 1.9415\n",
      "Epoch 3/5\n",
      "333330/333330 [==============================] - 62s 187us/step - loss: 1.9334\n",
      "Epoch 4/5\n",
      "333330/333330 [==============================] - 63s 188us/step - loss: 1.9269\n",
      "Epoch 5/5\n",
      "333330/333330 [==============================] - 65s 195us/step - loss: 1.9212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f736323b7b8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333330/333330 [==============================] - 63s 190us/step - loss: 1.9165\n",
      "Epoch 2/5\n",
      "333330/333330 [==============================] - 63s 188us/step - loss: 1.9121\n",
      "Epoch 3/5\n",
      "333330/333330 [==============================] - 66s 199us/step - loss: 1.9087\n",
      "Epoch 4/5\n",
      "333330/333330 [==============================] - 62s 187us/step - loss: 1.9053\n",
      "Epoch 5/5\n",
      "333330/333330 [==============================] - 62s 186us/step - loss: 1.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f734f378a58>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.save_weights('return_sequences_25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_every_char(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "\n",
    "#     index = [char_to_index[i] for i in inp]\n",
    "#     arr = np.expand_dims(index, axis=0)\n",
    "#     prediction = return_model.predict(arr)\n",
    "#     return ''.join([index_to_char[np.argmax(i)] for i in prediction[0]])\n",
    "    \n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        prediction = return_model.predict(arr)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    \n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'udt n rpini '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char('qor item i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

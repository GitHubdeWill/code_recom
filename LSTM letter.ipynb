{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import bcolz\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "# path = get_file(fname = 'allPyPrograms_no_comments.txt', origin = 'file:///homw/wtemp/585/allPyPrograms_no_comments.txt')\n",
    "path = os.getcwd() + '/allPyPrograms_no_comments.txt'\n",
    "text_all = open(path).read()\n",
    "text = text_all[:1000000]\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"def sort_blocks():     with open('README.md', 'r') as read_me_file:         \"\n",
      " 'read_me = read_me_file.read()     table_of_contents = '\n",
      " \"''.join(read_me.split('- - -')[0])     blocks = ''.join(read_me.split('- - \"\n",
      " \"-')[1]).split('\\\\n# ')     for i in range(len(blocks)):         if i == \"\n",
      " '0:             blocks[i]')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(text.replace(\"\\n\", \" \")[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(len(chars)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {v:i for i,v in enumerate(chars)}\n",
    "index_to_char = {i:v for i,v in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_index = [char_to_index[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70, 71, 72, 2, 85, 81, 84, 86, 65, 68]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def sort_blocks():\\n    wi'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index_to_char[i] for i in total_index[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num = 5\n",
    "xin = [[total_index[j+i] for j in range(0, len(total_index)-1-pred_num, pred_num)] for i in range(pred_num)]\n",
    "y = [total_index[i+pred_num] for i in range(0, len(total_index)-1-pred_num, pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.stack(xin[i][:-2]) for i in range(pred_num)]\n",
    "Y = np.stack(y[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([70, 81, 78, ..., 80,  2,  2]),\n",
      " array([71, 84, 81, ..., 14,  2,  2]),\n",
      " array([72, 86, 69, ...,  1,  2,  2]),\n",
      " array([ 2, 65, 77, ...,  2,  2,  2]),\n",
      " array([85, 68, 85, ...,  2,  2,  2])]\n"
     ]
    }
   ],
   "source": [
    "pprint(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81, 78, 10,  2, 86, 71, 39, 16])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199997,), (199997,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 256\n",
    "vocab_size = len(chars)+1\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#         Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "#         SimpleRNN(hidden_layers, activation='relu'),\n",
    "#         Dense(vocab_size, activation='softmax')\n",
    "#     ])\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "    LSTM(256),\n",
    "#     Dropout(0.5),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 5, 42)             10416     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 256)               306176    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 248)               63736     \n",
      "=================================================================\n",
      "Total params: 380,328\n",
      "Trainable params: 380,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "199997/199997 [==============================] - 88s 442us/step - loss: 1.1003\n",
      "Epoch 2/25\n",
      "199997/199997 [==============================] - 89s 443us/step - loss: 1.0488\n",
      "Epoch 3/25\n",
      "199997/199997 [==============================] - 88s 442us/step - loss: 1.0059\n",
      "Epoch 4/25\n",
      "199997/199997 [==============================] - 98s 491us/step - loss: 0.9709\n",
      "Epoch 5/25\n",
      "199997/199997 [==============================] - 89s 443us/step - loss: 0.9382\n",
      "Epoch 6/25\n",
      "199997/199997 [==============================] - 129s 647us/step - loss: 0.9096\n",
      "Epoch 7/25\n",
      "199997/199997 [==============================] - 180s 898us/step - loss: 0.8843\n",
      "Epoch 8/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.8619\n",
      "Epoch 9/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.8424\n",
      "Epoch 10/25\n",
      "199997/199997 [==============================] - 178s 892us/step - loss: 0.8257\n",
      "Epoch 11/25\n",
      "199997/199997 [==============================] - 180s 899us/step - loss: 0.8101\n",
      "Epoch 12/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.7955\n",
      "Epoch 13/25\n",
      "199997/199997 [==============================] - 179s 895us/step - loss: 0.7847\n",
      "Epoch 14/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.7731\n",
      "Epoch 15/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.7638\n",
      "Epoch 16/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.7564\n",
      "Epoch 17/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.7482\n",
      "Epoch 18/25\n",
      "199997/199997 [==============================] - 180s 898us/step - loss: 0.7403s - loss:\n",
      "Epoch 19/25\n",
      "199997/199997 [==============================] - 179s 895us/step - loss: 0.7352\n",
      "Epoch 20/25\n",
      "199997/199997 [==============================] - 180s 898us/step - loss: 0.7299\n",
      "Epoch 21/25\n",
      "199997/199997 [==============================] - 178s 892us/step - loss: 0.7235\n",
      "Epoch 22/25\n",
      "199997/199997 [==============================] - 179s 897us/step - loss: 0.7195\n",
      "Epoch 23/25\n",
      "199997/199997 [==============================] - 180s 899us/step - loss: 0.7152\n",
      "Epoch 24/25\n",
      "199997/199997 [==============================] - 179s 893us/step - loss: 0.7121\n",
      "Epoch 25/25\n",
      "199997/199997 [==============================] - 179s 896us/step - loss: 0.7077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c9152e0f0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.stack(X, 1), Y, batch_size=64, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_3predletter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_3predletter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_7predletter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_7predletter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(inp):\n",
    "    l = len(inp)\n",
    "    if l > pred_num:\n",
    "        inp = inp[-pred_num:]\n",
    "    if l < pred_num:\n",
    "        inp = \" \" * (pred_num-l) + inp\n",
    "    index = [char_to_index[i] for i in inp]\n",
    "    arr = np.expand_dims(np.array(index), axis=0)\n",
    "    prediction = model.predict(arr)\n",
    "    return index_to_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('\"t3fsdfjkdd\"4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = \"while True:\"\n",
    "for i in range(1000):\n",
    "    prog = prog + predict_next_char(prog[-pred_num:])\n",
    "prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_model1(observed_seq):\n",
    "    # Get the last letter\n",
    "    last_item = observed_seq[-1]\n",
    "    word = \"\"\n",
    "    thresh = 100\n",
    "    while thresh > 0 and (len(word) < 1 or word[-1] != \" \"):\n",
    "        thresh -= 1\n",
    "        if len(word) > 100:\n",
    "            return word\n",
    "        seen = observed_seq + word\n",
    "        p = predict_next_char(seen)\n",
    "        word = word + p\n",
    "        last_item = p\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy.py  has no hole to predict\n",
      "(b'', b'')\n",
      "(b'', b'')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 17, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,os\n",
    "import subprocess\n",
    "import evalerr\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "TEST_DIR = '/home/wtemp/585/error/Test_Dataset/'\n",
    "\n",
    "HOLE = \"PREDICTION_HOLE_PLACEHOLDER\"\n",
    "\n",
    "PRED_DIR = \"/home/wtemp/585/error/Predicted_Results/\"\n",
    "result_dict={}\n",
    "\n",
    "evalerr.test(recom_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [[total_index[j+i] for j in range(1, len(total_index)-pred_num, pred_num)] for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_return = [np.stack(ys[i][:-2]) for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 97\n",
    "n_fac = 42\n",
    "hidden_layers = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, return_sequences=True, activation='relu'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = np.stack(X, 1)\n",
    "Y_model = np.expand_dims(np.stack(Y_return, 1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.save_weights('return_sequences_25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_every_char(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "\n",
    "#     index = [char_to_index[i] for i in inp]\n",
    "#     arr = np.expand_dims(index, axis=0)\n",
    "#     prediction = return_model.predict(arr)\n",
    "#     return ''.join([index_to_char[np.argmax(i)] for i in prediction[0]])\n",
    "    \n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        prediction = return_model.predict(arr)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    \n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_every_char('qor item i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_model(observed_seq):\n",
    "    # Get the last letter\n",
    "    last_item = observed_seq[-1]\n",
    "    word = \"\"\n",
    "    thresh = 100\n",
    "    while thresh > 0 and (len(word) < 1 or word[-1] != \" \"):\n",
    "        thresh -= 1\n",
    "        if len(word) > 100:\n",
    "            return word\n",
    "        p = predict_every_char(last_item)\n",
    "        word = word + p\n",
    "        last_item = p\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import subprocess\n",
    "import evalerr\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "TEST_DIR = '/home/wtemp/585/error/Test_Dataset/'\n",
    "\n",
    "HOLE = \"PREDICTION_HOLE_PLACEHOLDER\"\n",
    "\n",
    "PRED_DIR = \"/home/wtemp/585/error/Predicted_Results/\"\n",
    "result_dict={}\n",
    "\n",
    "evalerr.test(recom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

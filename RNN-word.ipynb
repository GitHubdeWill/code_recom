{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import bcolz\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "# path = get_file(fname = 'allPyPrograms_no_comments.txt', origin = 'file:///homw/wtemp/585/allPyPrograms_no_comments.txt')\n",
    "path = os.getcwd() + '/allPyPrograms_no_comments.txt'\n",
    "text_all = open(path).read()\n",
    "text = text_all[:1000000]\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('def sort_blocks():\\n'\n",
      " \"    with open('README.md', 'r') as read_me_file:\\n\"\n",
      " '        read_me = read_me_file.read()\\n'\n",
      " \"    table_of_contents = ''.join(read_me.split('- - -')[0])\\n\"\n",
      " \"    blocks = ''.join(read_me.split('- - -')[1]).split('\\\\n# ')\\n\"\n",
      " '    for i in range(len(blocks)):\\n'\n",
      " '        if i == 0:\\n'\n",
      " '            blocks[i]')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108118\n"
     ]
    }
   ],
   "source": [
    "words = re.findall(r\"[\\w']+\", text)\n",
    "print(len(words)+1)\n",
    "words.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'sort_blocks', 'with', 'open', \"'README\", \"md'\", \"'r'\", 'as', 'read_me_file', 'read_me', 'read_me_file', 'read', 'table_of_contents', \"''\", 'join', 'read_me', 'split', \"'\", \"'\", '0', 'blocks', \"''\", 'join', 'read_me', 'split', \"'\", \"'\", '1', 'split', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {v:i for i,v in enumerate(words)}\n",
    "index_to_char = {i:v for i,v in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_index = [char_to_index[w] for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[108064, 192, 107351, 79735, 53640, 23669, 78978, 104042, 117, 125]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"defsort_blockswithopen'READMEmd''r'asread_me_fileread_meread_me_filereadtable_of_contents''joinread_mesplit''0blocks''joinread_mesplit\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index_to_char[i] for i in total_index[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num = 3\n",
    "xin = [[total_index[j+i] for j in range(0, len(total_index)-1-pred_num, pred_num)] for i in range(pred_num)]\n",
    "y = [total_index[i+pred_num] for i in range(0, len(total_index)-1-pred_num, pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.stack(xin[i][:-2]) for i in range(pred_num)]\n",
    "Y = np.stack(y[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([108064,  79735,  78978, ..., 108099, 108102, 108105]),\n",
      " array([   192,  53640, 104042, ..., 108100, 108103, 108106]),\n",
      " array([107351,  23669,    117, ..., 108101, 108104, 108107])]\n"
     ]
    }
   ],
   "source": [
    "pprint(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79735,  78978,    125,     90,    125, 108059, 105345,  99520])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36036,), (36036,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 256\n",
    "vocab_size = len(words)\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, activation='relu'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3, 42)             4540956   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 108118)            27786326  \n",
      "=================================================================\n",
      "Total params: 32,403,826\n",
      "Trainable params: 32,403,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36036/36036 [==============================] - 532s 15ms/step - loss: 8.3777\n",
      "Epoch 2/20\n",
      "36036/36036 [==============================] - 462s 13ms/step - loss: 7.1828\n",
      "Epoch 3/20\n",
      "36036/36036 [==============================] - 461s 13ms/step - loss: 5.7046\n",
      "Epoch 5/20\n",
      "36036/36036 [==============================] - 461s 13ms/step - loss: 4.8496\n",
      "Epoch 6/20\n",
      "36036/36036 [==============================] - 461s 13ms/step - loss: 3.9133\n",
      "Epoch 7/20\n",
      "36036/36036 [==============================] - 461s 13ms/step - loss: 2.9620\n",
      "Epoch 8/20\n",
      "36036/36036 [==============================] - 461s 13ms/step - loss: 2.2022\n",
      "Epoch 9/20\n",
      "36036/36036 [==============================] - 461s 13ms/step - loss: 1.7199\n",
      "Epoch 10/20\n",
      "36036/36036 [==============================] - 462s 13ms/step - loss: 1.4154\n",
      "Epoch 11/20\n",
      "36036/36036 [==============================] - 465s 13ms/step - loss: 1.1917\n",
      "Epoch 12/20\n",
      "36036/36036 [==============================] - 462s 13ms/step - loss: 1.0361\n",
      "Epoch 13/20\n",
      "36036/36036 [==============================] - 462s 13ms/step - loss: 0.9020\n",
      "Epoch 14/20\n",
      "36036/36036 [==============================] - 464s 13ms/step - loss: 0.8055\n",
      "Epoch 15/20\n",
      "36036/36036 [==============================] - 610s 17ms/step - loss: 0.7259\n",
      "Epoch 16/20\n",
      "36036/36036 [==============================] - 575s 16ms/step - loss: 0.6621\n",
      "Epoch 17/20\n",
      "36036/36036 [==============================] - 473s 13ms/step - loss: 0.6110\n",
      "Epoch 18/20\n",
      "36036/36036 [==============================] - 576s 16ms/step - loss: 0.5636\n",
      "Epoch 19/20\n",
      "36036/36036 [==============================] - 767s 21ms/step - loss: 0.5316\n",
      "Epoch 20/20\n",
      "36036/36036 [==============================] - 570s 16ms/step - loss: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64b1af7048>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.stack(X, 1), Y, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_3predword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_3predword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_7predword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_7predword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(inp):\n",
    "    inp = re.findall(r\"[\\w']+\", inp)\n",
    "    for i in range(len(inp)):\n",
    "        if inp[i] not in char_to_index.keys():\n",
    "            inp[i] = \"\"\n",
    "    l = len(inp)\n",
    "    if l > pred_num:\n",
    "        inp = inp[-pred_num:]\n",
    "    if l < pred_num:\n",
    "        for i in range(pred_num-l):\n",
    "            inp.insert(0, \"\")\n",
    "#     print(len(inp))\n",
    "    index = [char_to_index[i] for i in inp]\n",
    "    arr = np.expand_dims(np.array(index), axis=0)\n",
    "    prediction = model.predict(arr)\n",
    "    return index_to_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'self'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('def main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('l = len( arr ) arr.insert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while True: param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param param'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = \"while True:\"\n",
    "for i in range(100):\n",
    "    prog = prog +\" \"+ predict_next_char(prog[-pred_num:])\n",
    "prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_model1(observed_seq):\n",
    "    # Get the last letter\n",
    "    last_item = observed_seq[-1]\n",
    "    word = \"\"\n",
    "    thresh = 100\n",
    "    while thresh > 0 and (len(word) < 1 or word[-1] != \" \"):\n",
    "        thresh -= 1\n",
    "        if len(word) > 100:\n",
    "            return word\n",
    "        seen = observed_seq + word\n",
    "        p = predict_next_char(seen)\n",
    "        word = word + p\n",
    "        last_item = p\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy.py  has no hole to predict\n",
      "(b'', b'')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 16, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,os\n",
    "import subprocess\n",
    "import evalerr\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "TEST_DIR = '/home/wtemp/585/error/Test_Dataset/'\n",
    "\n",
    "HOLE = \"PREDICTION_HOLE_PLACEHOLDER\"\n",
    "\n",
    "PRED_DIR = \"/home/wtemp/585/error/Predicted_Results/\"\n",
    "result_dict={}\n",
    "\n",
    "evalerr.test(recom_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [[total_index[j+i] for j in range(1, len(total_index)-pred_num, pred_num)] for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_return = [np.stack(ys[i][:-2]) for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 97\n",
    "n_fac = 42\n",
    "hidden_layers = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, return_sequences=True, activation='relu'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = np.stack(X, 1)\n",
    "Y_model = np.expand_dims(np.stack(Y_return, 1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_model.save_weights('return_sequences_25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_every_char(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "\n",
    "#     index = [char_to_index[i] for i in inp]\n",
    "#     arr = np.expand_dims(index, axis=0)\n",
    "#     prediction = return_model.predict(arr)\n",
    "#     return ''.join([index_to_char[np.argmax(i)] for i in prediction[0]])\n",
    "    \n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        prediction = return_model.predict(arr)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    \n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_every_char('qor item i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recom_model(observed_seq):\n",
    "    # Get the last letter\n",
    "    last_item = observed_seq[-1]\n",
    "    word = \"\"\n",
    "    thresh = 100\n",
    "    while thresh > 0 and (len(word) < 1 or word[-1] != \" \"):\n",
    "        thresh -= 1\n",
    "        if len(word) > 100:\n",
    "            return word\n",
    "        p = predict_every_char(last_item)\n",
    "        word = word + p\n",
    "        last_item = p\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import subprocess\n",
    "import evalerr\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "TEST_DIR = '/home/wtemp/585/error/Test_Dataset/'\n",
    "\n",
    "HOLE = \"PREDICTION_HOLE_PLACEHOLDER\"\n",
    "\n",
    "PRED_DIR = \"/home/wtemp/585/error/Predicted_Results/\"\n",
    "result_dict={}\n",
    "\n",
    "evalerr.test(recom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
